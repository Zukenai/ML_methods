## Описание ноутбуков

### Lab1.ipynb  
**Тема:** Загрузка и предобработка данных  
1. **Загрузка наборов данных**  
   - Используем встроенные датасеты `scikit-learn` (например, Iris, Boston Housing) и внешние CSV-файлы (через `pandas.read_csv`).  
   - Пояснения по работе с путями и параметрами загрузки (`sep`, `header`, `index_col`).  
2. **Первичный анализ**  
   - Вычисление описательных статистик: среднее, медиана, стандартное отклонение, квартили с помощью `DataFrame.describe()`.  
   - Построение гистограмм и ящиков с усами (`matplotlib`, `seaborn`) для оценки распределения признаков.  
   - Диаграммы разброса (scatter plots) для анализа корреляций между переменными.  
3. **Предобработка данных**  
   - Обнаружение и работа с пропущенными значениями: методы удаления (`dropna`) и заполнения (`fillna`, `SimpleImputer`).  
   - Кодирование категориальных признаков: one-hot (`pd.get_dummies`), label encoding (`LabelEncoder`).  
   - Масштабирование и нормализация признаков: `StandardScaler`, `MinMaxScaler`.  
   - Разбиение данных на тренировочную и тестовую выборки (`train_test_split`).

---

### Lab2.ipynb  
**Тема:** Классификация  
1. **k-Nearest Neighbors (k-NN)**  
   - Принцип работы алгоритма: расстояние Евклида, выбор k.  
   - Подбор гиперпараметра k через кросс-валидацию (`GridSearchCV`).  
   - Визуализация границ принятия решений на двумерном датасете.  
2. **Логистическая регрессия**  
   - Математическая модель: логит-функция, максимизация правдоподобия.  
   - Регуляризация L1 и L2, влияние параметра `C`.  
   - Интерпретация коэффициентов модели и оценка значимости признаков.  
3. **Деревья решений и метрики**  
   - Построение дерева с помощью `DecisionTreeClassifier`: критерии разбиения (gini, энтропия).  
   - Вычисление метрик качества: accuracy, precision, recall, F1-score (`classification_report`).  
   - Применение k-fold кросс-валидации для оценки устойчивости модели.

---

### Lab3.ipynb  
**Тема:** Регрессия  
1. **Линейная регрессия**  
   - Модель наименьших квадратов (`LinearRegression`): формула, предпосылки модели.  
   - Оценка качества: MSE, RMSE, коэффициент детерминации R².  
   - Визуализация фактических vs. предсказанных значений.  
2. **Полиномиальная регрессия**  
   - Преобразование признаков с помощью `PolynomialFeatures`.  
   - Риск переобучения при высоких степенях полинома и способы его контроля.  
3. **Сравнение моделей**  
   - Сравнение линейной и полиномиальной моделей на одной и той же выборке.  
   - График зависимости ошибки от степени полинома.  
   - Кросс-валидация для оценки стабильности разных степеней.

---

### lab 4.ipynb  
**Тема:** Кластеризация  
1. **Алгоритм k-means**  
   - Суть метода: случайная инициализация центроид, итеративное обновление.  
   - Подбор числа кластеров через метод локтя (elbow method).  
   - Визуализация кластеров и центров на двумерном наборе данных.  
2. **Иерархическая кластеризация**  
   - Агиометрический подход (agglomerative): выбор связности (ward, complete, average).  
   - Построение дендрограммы (`scipy.cluster.hierarchy`).  
   - Обрезка дендрограммы для получения фиксированного числа кластеров.  
3. **Оценка качества кластеризации**  
   - Силуэтный анализ: коэффициент силуэта для разных k.  
   - Внутрикластерное расстояние и межкластерная разобщённость.

---

### lab5.ipynb  
**Тема:** Ансамблевые методы  
1. **Bagging и Random Forest**  
   - Bootstrap-агрегация (bagging): снижение дисперсии модели.  
   - Построение случайного леса: случайный подбор признаков при разбиении.  
   - Оценка важности признаков (`feature_importances_`).  
2. **Градиентный бустинг (Gradient Boosting Machines)**  
   - Принцип: последовательное обучение «слабых» моделей на остатках.  
   - Настройка параметров: количество деревьев, глубина, скорость обучения.  
   - Сравнение с Random Forest по качеству и времени обучения.  
3. **Сравнительный анализ**  
   - Таблица результатов моделей на одном и том же датасете.  
   - График зависимости качества от числа деревьев и глубины.  
   - Выводы о применимости каждого метода в разных задачах.

---

### Предсказание диабета.ipynb  
**Тема:** Кейс-стади на реальных данных  
1. **Исследование данных о пациентах**  
   - Источник данных: открытый набор Pima Indians Diabetes Database.  
   - Описание признаков: возраст, индекс массы тела, уровень глюкозы и др.  
   - Первичный анализ: корреляции, распределения, пропуски и выбросы.  
2. **Построение моделей**  
   - Логистическая регрессия: подбор регуляризации, интерпретация odds ratio.  
   - Деревья решений: визуализация структуры дерева, анализ ветвлений.  
   - Опционально: сравнение с k-NN и Random Forest.  
3. **Оценка и сравнение**  
   - Метрики: ROC-AUC, precision-recall, confusion matrix.  
   - Построение ROC-кривой и PR-кривой.  
   - Кросс-валидация и выводы о стабильности моделей.
